"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[80321],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>h});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),d=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=d(e.components);return a.createElement(s.Provider,{value:t},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=d(n),m=r,h=u["".concat(s,".").concat(m)]||u[m]||c[m]||o;return n?a.createElement(h,i(i({ref:t},p),{},{components:n})):a.createElement(h,i({ref:t},p))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[u]="string"==typeof e?e:r,i[1]=l;for(var d=2;d<o;d++)i[d]=n[d];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},2606:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>l,toc:()=>d});var a=n(87462),r=(n(67294),n(3905));const o={},i="How to build a deep learning model in 15 minutes",l={unversionedId:"Python/How to build a deep learning model in 15 minutes",id:"Python/How to build a deep learning model in 15 minutes",title:"How to build a deep learning model in 15 minutes",description:"https://tech.instacart.com/how-to-build-a-deep-learning-model-in-15-minutes-a3684c6f71e",source:"@site/docs/Python/How to build a deep learning model in 15 minutes.md",sourceDirName:"Python",slug:"/Python/How to build a deep learning model in 15 minutes",permalink:"/notebook/docs/Python/How to build a deep learning model in 15 minutes",draft:!1,editUrl:"https://github.com/scheffershen/notebook/tree/main/docs/Python/How to build a deep learning model in 15 minutes.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"How to Easily Summarize Audio and Video Files in Python",permalink:"/notebook/docs/Python/How to Easily Summarize Audio and Video Files in Python"},next:{title:"Installing packages using pip and virtual environments",permalink:"/notebook/docs/Python/Installing packages using pip and virtual environments"}},s={},d=[{value:"A common feeling in Machine Learning:",id:"a-common-feeling-in-machine-learning",level:2},{value:"TLDR",id:"tldr",level:2},{value:"Feature Specs",id:"feature-specs",level:2},{value:"15 minute Outline",id:"15-minute-outline",level:2},{value:"1) Create a new app",id:"1-create-a-new-app",level:2},{value:"2) Designing a Model",id:"2-designing-a-model",level:2},{value:"3) Generate a scaffold",id:"3-generate-a-scaffold",level:2}],p={toc:d};function u(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"how-to-build-a-deep-learning-model-in-15-minutes"},"How to build a deep learning model in 15 minutes"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://tech.instacart.com/how-to-build-a-deep-learning-model-in-15-minutes-a3684c6f71e"},"https://tech.instacart.com/how-to-build-a-deep-learning-model-in-15-minutes-a3684c6f71e")),(0,r.kt)("h2",{id:"a-common-feeling-in-machine-learning"},"A common feeling in Machine Learning:"),(0,r.kt)("p",null,"Common Problems"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Performance bottlenecks are easy to hit when you\u2019re writing bespoke code at high levels like Python or SQL."),(0,r.kt)("li",{parentName:"ol"},"Code Complexity grows because valuable models are the result of many iterative changes, making individual insights harder to maintain and communicate as the code evolves in an unstructured way."),(0,r.kt)("li",{parentName:"ol"},"Repeatability suffers as data and library dependencies are constantly in flux."),(0,r.kt)("li",{parentName:"ol"},"Information overload makes it easy to miss newly available low hanging fruit when trying to keep up with the latest papers, packages, features, bugs\u2026 it\u2019s much worse for people just entering the field.")),(0,r.kt)("h2",{id:"tldr"},"TLDR"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},'$ pip3 install lore\n$ git clone https://github.com/montanalow/my_app.git\n$ cd my_app \n$ lore install # caching all dependencies locally takes a few minutes the first time\n$ lore server & \n$ curl "http://localhost:5000/product_popularity.Keras/predict.json?product_name=Banana&department=produce"\n')),(0,r.kt)("h2",{id:"feature-specs"},"Feature Specs"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Models support hyper parameter search over estimators with a data pipeline. They will efficiently utilize multiple GPUs (if available) with a couple different strategies, and can be saved and distributed for horizontal scalability."),(0,r.kt)("li",{parentName:"ul"},"Estimators from multiple packages are supported: Keras, XGBoost and SciKit Learn. They can all be subclassed with build, fit or predict overridden to completely customize your algorithm and architecture, while still benefiting from everything else."),(0,r.kt)("li",{parentName:"ul"},"Pipelines avoid information leaks between train and test sets, and one pipeline allows experimentation with many different estimators. A disk based pipeline is available if you exceed your machines available RAM."),(0,r.kt)("li",{parentName:"ul"},"Transformers standardize advanced feature engineering. For example, convert an American first name to its statistical age or gender using US Census data. Extract the geographic area code from a free form phone number string. Common date, time and string operations are supported efficiently through pandas."),(0,r.kt)("li",{parentName:"ul"},"Encoders offer robust input to your estimators, and avoid common problems with missing and long tail values. They are well tested to save you from garbage in/garbage out."),(0,r.kt)("li",{parentName:"ul"},"IO connections are configured and pooled in a standard way across the app for popular (no)sql databases, with transaction management and read write optimizations for bulk data, rather than typical ORM single row operations. Connections share a configurable query cache, in addition to encrypted S3 buckets for distributing models and datasets."),(0,r.kt)("li",{parentName:"ul"},"Dependency Management for each individual app in development, that can be 100% replicated to production. No manual activation, or magic env vars, or hidden files that break python for everything else. No knowledge required of venv, pyenv, pyvenv, virtualenv, virtualenvwrapper, pipenv, conda. Ain\u2019t nobody got time for that."),(0,r.kt)("li",{parentName:"ul"},"Tests for your models can be run in your Continuous Integration environment, allowing Continuous Deployment for code and training updates, without increased work for your infrastructure team."),(0,r.kt)("li",{parentName:"ul"},"Workflow Support whether you prefer the command line, a python console, jupyter notebook, or IDE. Every environment gets readable logging and timing statements configured for both production and development.")),(0,r.kt)("h2",{id:"15-minute-outline"},"15 minute Outline"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Create a new app (3 min)"),(0,r.kt)("li",{parentName:"ol"},"Design a model (1 min)"),(0,r.kt)("li",{parentName:"ol"},"Generate a scaffold (2 min)"),(0,r.kt)("li",{parentName:"ol"},"Implement a pipeline (5 min)"),(0,r.kt)("li",{parentName:"ol"},"Test the code (1 min)"),(0,r.kt)("li",{parentName:"ol"},"Train the model (1 min)"),(0,r.kt)("li",{parentName:"ol"},"Deploy to production (2 min)")),(0,r.kt)("h2",{id:"1-create-a-new-app"},"1) Create a new app"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"# On Linux\n$ pip install lore\n# On OS X use homebrew python 2 or 3\n$ brew install python3 && pip3 install lore\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ lore init my_app --python-version=3.6.4 --keras\n")),(0,r.kt)("h2",{id:"2-designing-a-model"},"2) Designing a Model"),(0,r.kt)("h2",{id:"3-generate-a-scaffold"},"3) Generate a scaffold"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ cd my_app\n$ lore generate scaffold product_popularity --keras --regression --holdout\n")),(0,r.kt)("p",null,"##4) Implement a Pipeline"),(0,r.kt)("p",null,"Here is the implementation of get_data:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# my_app/pipelines/product_popularity.py part 1\n\nimport os\n\nfrom lore.encoders import Token, Unique, Norm\nimport lore.io\nimport lore.pipelines\nimport lore.env\n\nimport pandas\n\n\nclass Holdout(lore.pipelines.holdout.Base):\n    # You can inspect the source data csv's yourself from the command line with:\n    # $ wget https://s3.amazonaws.com/instacart-datasets/instacart_online_grocery_shopping_2017_05_01.tar.gz\n    # $ tar -xzvf instacart_online_grocery_shopping_2017_05_01.tar.gz\n\n    def get_data(self):\n        url = 'https://s3.amazonaws.com/instacart-datasets/instacart_online_grocery_shopping_2017_05_01.tar.gz'\n\n        # Lore will extract and cache files in lore.env.data_dir by default\n        lore.io.download(url, cache=True, extract=True)\n        \n        # Defined to DRY up paths to 3rd party file hierarchy\n        def read_csv(name):\n            path = os.path.join(\n                lore.env.data_dir,\n                'instacart_2017_05_01',\n                name + '.csv')\n            return pandas.read_csv(path, encoding='utf8')\n        \n        # Published order data was split into irrelevant prior/train\n        # sets, so we will combine them to re-purpose all the data.\n        orders = read_csv('order_products__prior')\n        orders = orders.append(read_csv('order_products__train'))\n\n        # count how many times each product_id was ordered\n        data = orders.groupby('product_id').size().to_frame('sales')\n\n        # add product names and department ids to ordered product ids\n        products = read_csv('products').set_index('product_id')\n        data = data.join(products)\n\n        # add department names to the department ids\n        departments = read_csv('departments').set_index('department_id')\n        data = data.set_index('department_id').join(departments)\n        \n        # Only return the columns we need for training\n        data = data.reset_index()\n        return data[['product_name', 'department', 'sales']]\n")))}u.isMDXComponent=!0}}]);
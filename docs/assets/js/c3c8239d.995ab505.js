"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[28293],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>g});var o=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,o,i=function(e,t){if(null==e)return{};var n,o,i={},r=Object.keys(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var a=o.createContext({}),u=function(e){var t=o.useContext(a),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},c=function(e){var t=u(e.components);return o.createElement(a.Provider,{value:t},e.children)},p="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},m=o.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,a=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),p=u(n),m=i,g=p["".concat(a,".").concat(m)]||p[m]||d[m]||r;return n?o.createElement(g,s(s({ref:t},c),{},{components:n})):o.createElement(g,s({ref:t},c))}));function g(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,s=new Array(r);s[0]=m;var l={};for(var a in t)hasOwnProperty.call(t,a)&&(l[a]=t[a]);l.originalType=e,l[p]="string"==typeof e?e:i,s[1]=l;for(var u=2;u<r;u++)s[u]=n[u];return o.createElement.apply(null,s)}return o.createElement.apply(null,n)}m.displayName="MDXCreateElement"},31769:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>a,contentTitle:()=>s,default:()=>p,frontMatter:()=>r,metadata:()=>l,toc:()=>u});var o=n(87462),i=(n(67294),n(3905));const r={},s="API Cloud Vision",l={unversionedId:"Google API/Google Vision/IA_vision",id:"Google API/Google Vision/IA_vision",title:"API Cloud Vision",description:"L'API Cloud Vision fournit un ensemble de fonctionnalit\xe9s pour l'analyse des images. Dans toutes ces situations, vous ne paierez que ce que vous utilisez sans engagement pr\xe9alable. Les fonctionnalit\xe9s suivantes sont disponibles avec l'API :",source:"@site/docs/Google API/Google Vision/IA_vision.md",sourceDirName:"Google API/Google Vision",slug:"/Google API/Google Vision/IA_vision",permalink:"/notebook/docs/Google API/Google Vision/IA_vision",draft:!1,editUrl:"https://github.com/scheffershen/notebook/tree/main/docs/Google API/Google Vision/IA_vision.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Google Vision API",permalink:"/notebook/docs/category/google-vision-api"},next:{title:"Resources",permalink:"/notebook/docs/Google API/Google Vision/Resources"}},a={},u=[{value:"Type de fonctionnalit\xe9",id:"type-de-fonctionnalit\xe9",level:3},{value:"Limites",id:"limites",level:3}],c={toc:u};function p(e){let{components:t,...n}=e;return(0,i.kt)("wrapper",(0,o.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"api-cloud-vision"},"API Cloud Vision"),(0,i.kt)("p",null,"L'API Cloud Vision fournit un ensemble de fonctionnalit\xe9s pour l'analyse des images. Dans toutes ces situations, vous ne paierez que ce que vous utilisez sans engagement pr\xe9alable. Les fonctionnalit\xe9s suivantes sont disponibles avec l'API :"),(0,i.kt)("h3",{id:"type-de-fonctionnalit\xe9"},"Type de fonctionnalit\xe9"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"CROP_HINTS"),": Sugg\xe8re des sommets pour cadrer une zone d'une image.\n",(0,i.kt)("inlineCode",{parentName:"p"},"DOCUMENT_TEXT_DETECTION"),": Ex\xe9cute la reconnaissance optique de caract\xe8res (OCR) sur des images de texte dense, telles que des documents (PDF/TIFF) et des images contenant du texte manuscrit. TEXT_DETECTION peut \xeatre utilis\xe9 pour les images de texte \xe9pars. Prioritaire lorsque DOCUMENT_TEXT_DETECTION et TEXT_DETECTION sont pr\xe9sents.\n",(0,i.kt)("inlineCode",{parentName:"p"},"TEXT_DETECTION"),": Effectue une reconnaissance optique des caract\xe8res (OCR) sur le texte de l'image. La d\xe9tection de texte est optimis\xe9e pour les zones de texte \xe9pars dans une image plus grande. Si l'image est un document (PDF/TIFF), si elle contient du texte dense ou qu'elle contient une \xe9criture manuscrite, utilisez plut\xf4t DOCUMENT_TEXT_DETECTION."),(0,i.kt)("h3",{id:"limites"},"Limites"),(0,i.kt)("p",null,"Les limites d'utilisation ci-dessous sont appliqu\xe9es \xe0 l'API Vision :"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Taille du fichier image: 20 Mo"),(0,i.kt)("li",{parentName:"ul"},"Taille de l'objet de requ\xeate JSON: 10 Mo"),(0,i.kt)("li",{parentName:"ul"},"Nombre d'images par requ\xeate: 16")),(0,i.kt)("p",null,"Les images encod\xe9es en Base64 peuvent d\xe9passer la limite de taille JSON, m\xeame si elles sont comprises dans la limite de la taille du fichier image. Les images plus volumineuses doivent \xeatre h\xe9berg\xe9es sur Cloud Storage ou sur une URL accessible publiquement. Notez que la taille de fichier des images encod\xe9es en Base64 peut \xeatre sup\xe9rieure \xe0 celle du fichier image d'origine (d'environ 37 %, g\xe9n\xe9ralement)."))}p.isMDXComponent=!0}}]);
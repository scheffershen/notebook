"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1593],{3905:(e,n,t)=>{t.d(n,{Zo:()=>p,kt:()=>y});var r=t(7294);function s(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function a(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){s(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function o(e,n){if(null==e)return{};var t,r,s=function(e,n){if(null==e)return{};var t,r,s={},i=Object.keys(e);for(r=0;r<i.length;r++)t=i[r],n.indexOf(t)>=0||(s[t]=e[t]);return s}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)t=i[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(s[t]=e[t])}return s}var c=r.createContext({}),l=function(e){var n=r.useContext(c),t=n;return e&&(t="function"==typeof e?e(n):a(a({},n),e)),t},p=function(e){var n=l(e.components);return r.createElement(c.Provider,{value:n},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},h=r.forwardRef((function(e,n){var t=e.components,s=e.mdxType,i=e.originalType,c=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),u=l(t),h=s,y=u["".concat(c,".").concat(h)]||u[h]||d[h]||i;return t?r.createElement(y,a(a({ref:n},p),{},{components:t})):r.createElement(y,a({ref:n},p))}));function y(e,n){var t=arguments,s=n&&n.mdxType;if("string"==typeof e||s){var i=t.length,a=new Array(i);a[0]=h;var o={};for(var c in n)hasOwnProperty.call(n,c)&&(o[c]=n[c]);o.originalType=e,o[u]="string"==typeof e?e:s,a[1]=o;for(var l=2;l<i;l++)a[l]=t[l];return r.createElement.apply(null,a)}return r.createElement.apply(null,t)}h.displayName="MDXCreateElement"},2790:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>i,metadata:()=>o,toc:()=>l});var r=t(7462),s=(t(7294),t(3905));const i={},a=void 0,o={unversionedId:"Python/Elasticsearch-backup/backup",id:"Python/Elasticsearch-backup/backup",title:"backup",description:"",source:"@site/docs/Python/Elasticsearch-backup/backup.md",sourceDirName:"Python/Elasticsearch-backup",slug:"/Python/Elasticsearch-backup/backup",permalink:"/notebook/docs/Python/Elasticsearch-backup/backup",draft:!1,editUrl:"https://github.com/scheffershen/notebook/tree/main/docs/Python/Elasticsearch-backup/backup.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"README",permalink:"/notebook/docs/Python/Elasticsearch-backup/"},next:{title:"es-searchly-backup",permalink:"/notebook/docs/Python/Elasticsearch-backup/es-searchly-backup"}},c={},l=[],p={toc:l};function u(e){let{components:n,...t}=e;return(0,s.kt)("wrapper",(0,r.Z)({},p,t,{components:n,mdxType:"MDXLayout"}),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'#!/usr/bin/python\n\n# Dependencies\nimport sys\nimport os\nimport time\nimport json\nimport tarfile\nimport shutil\nimport requests\n\n# Help text\nif len(sys.argv) < 2:\n    print "Usage:"\n    print " python backup.py (indexname)"\n    print " python backup.py (indexname) (elasticsearch host)"\n    print " python backup.py (indexname) (elasticsearch host) (elasticsearch port)"\n    exit(1)\n\n# Get the elasticsearch server\nif len(sys.argv) > 2:\n    host = sys.argv[2]\n    if len(sys.argv) > 3:\n        port = sys.argv[3]\n    else:\n        port = "9200"\nelse:\n    host = "localhost"\n    port = "9200"\nurl = "http://%s:%s" % (host, port)\nprint "Using ElasticSearch at %s" % url\n\ntry:\n    r = requests.get(url)\n    if r.status_code != 200:\n        print "Error hitting ElasticSearch on %s, response code was %i" % (url, r.status_code)\n        exit(1)\n    else:\n        print "Verified ElasticSearch server"\nexcept:\n    print "Unable to hit ElasticSearch on %s" % url\n    exit(1)\n\n# Check with the user\nindex = sys.argv[1]\nprint "Backing up index \'%s\'" % index\nprint "Ctrl+C now to abort..."\n\ntime.sleep(3)\n\n# Make the directories we need\nprint "Checking write permission to current directory"\ntry:\n    os.mkdir(index)\n    os.mkdir("%s/data" % index)\nexcept:\n    print "Unable to write to the current directory, please resolve this and try again"\n    exit(1)\n\n# Download and save the settings\nprint "Downloading \'%s\' settings" % index\n\nr = requests.get("%s/%s/_settings" % (url, index))\nif r.status_code != 200:\n        print "Unable to get settings for index \'%s\', error code: %i" % (index, r.status_code)\n        exit(1)\n\nsettings_file = open("%s/settings" % index, "w")\nsettings_file.write(r.content)\nsettings_file.close()\n\n# Download and save the schema\nprint "Downloading \'%s\' schema" % index\n\nr = requests.get("%s/%s/_mapping" % (url, index))\nif r.status_code != 200:\n    print "Unable to get schema for index \'%s\', error code: %i" % (index, r.status_code)\n    exit(1)\n\nschema_file = open("%s/schema" % index, "w")\nschema_file.write(r.content)\nschema_file.close()\n\n# Download the data\nquery = {}\nquery["query"] = {}\nquery["query"]["indices"] = {}\nquery["query"]["indices"]["indices"] = [index]\nquery["query"]["indices"]["query"] = {}\nquery["query"]["indices"]["query"]["match_all"] = {}\nquery = json.dumps(query)\n\nr = requests.get("%s/_search?search_type=scan&scroll=10m&size=100" % url, data=query)\ndata = json.loads(r.content)\nscroll_id = data["_scroll_id"]\n\nfinished = False\ncount = 0\n\nwhile not finished:\n\n    count = count + 1\n    r = requests.get("%s/_search/scroll?scroll=10m" % url, data=scroll_id)\n    content = json.loads(r.content)\n    scroll_id = content["_scroll_id"]\n    number = len(content["hits"]["hits"])\n    print "Pass %i: Got %i results" % (count, number)\n    \n    if number < 1:\n        finished = True\n    else:\n        data_file = open("%s/data/%i" % (index, count), "w")\n        data_file.write(json.dumps(content["hits"]["hits"]))\n        data_file.close()\n\n# Zip up the data\nfilename = "%s.esbackup" % index\ntar = tarfile.open(filename, "w:gz")\ntar.add(index)\ntar.close()\n\n# Delete the directory\nshutil.rmtree(index)\n\nprint "Complete. Your file is:"\nprint filename\nexit(0)\n')))}u.isMDXComponent=!0}}]);
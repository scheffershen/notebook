"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[47401],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>h});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var c=a.createContext({}),s=function(e){var t=a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},d=function(e){var t=s(e.components);return a.createElement(c.Provider,{value:t},e.children)},u="mdxType",g={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,c=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),u=s(n),p=r,h=u["".concat(c,".").concat(p)]||u[p]||g[p]||o;return n?a.createElement(h,l(l({ref:t},d),{},{components:n})):a.createElement(h,l({ref:t},d))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,l=new Array(o);l[0]=p;var i={};for(var c in t)hasOwnProperty.call(t,c)&&(i[c]=t[c]);i.originalType=e,i[u]="string"==typeof e?e:r,l[1]=i;for(var s=2;s<o;s++)l[s]=n[s];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},47795:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>o,metadata:()=>i,toc:()=>s});var a=n(87462),r=(n(67294),n(3905));const o={},l="4-Python-libraries-to-detect-English-and-Non-English-language",i={unversionedId:"Python/Python-libraries-to-detect-English-and-Non-English-language",id:"Python/Python-libraries-to-detect-English-and-Non-English-language",title:"4-Python-libraries-to-detect-English-and-Non-English-language",description:"We will discuss spacy-langdetect, Pycld2, TextBlob, and Googletrans for language detection",source:"@site/docs/Python/4-Python-libraries-to-detect-English-and-Non-English-language.md",sourceDirName:"Python",slug:"/Python/Python-libraries-to-detect-English-and-Non-English-language",permalink:"/notebook/docs/Python/Python-libraries-to-detect-English-and-Non-English-language",draft:!1,editUrl:"https://github.com/scheffershen/notebook/tree/main/docs/Python/4-Python-libraries-to-detect-English-and-Non-English-language.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Python RoadMap",permalink:"/notebook/docs/Python/Python-RoadMap"},next:{title:"Elasticsearch backup",permalink:"/notebook/docs/category/elasticsearch-backup"}},c={},s=[{value:"spacy-langdetect",id:"spacy-langdetect",level:2},{value:"Pycld2",id:"pycld2",level:2},{value:"TextBlob",id:"textblob",level:2},{value:"Googletrans",id:"googletrans",level:2},{value:"Resources",id:"resources",level:2}],d={toc:s};function u(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"4-python-libraries-to-detect-english-and-non-english-language"},"4-Python-libraries-to-detect-English-and-Non-English-language"),(0,r.kt)("p",null,"We will discuss spacy-langdetect, Pycld2, TextBlob, and Googletrans for language detection"),(0,r.kt)("h2",{id:"spacy-langdetect"},"spacy-langdetect"),(0,r.kt)("p",null,"You need to install the ",(0,r.kt)("inlineCode",{parentName:"p"},"spacy-langdetect")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"spacy")," python libraries for the below code to work."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from spacy_langdetect import LanguageDetector\n\nimport spacy\n\nnlp = spacy.load('en')  # 1\nnlp.add_pipe(LanguageDetector(), name='language_detector', last=True) #2\ntext_content = \"Er lebt mit seinen Eltern und seiner Schwester in Berlin.\"\ndoc = nlp(text_content) #3\ndetect_language = doc._.language #4\nprint(detect_language)\n{'language': 'de', 'score': 0.9999958526911192}\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from langdetect import detect, detect_langs\n\ndef language_detection(text, method = "single"):\n\n  """\n  @desc: \n    - detects the language of a text\n  @params:\n    - text: the text which language needs to be detected\n    - method: detection method: \n      single: if the detection is based on the first option (detect)\n  @return:\n    - the langue/list of languages\n  """\n\n  if(method.lower() != "single"):\n    result = detect_langs(text)\n\n  else:\n    result = detect(text)\n\n  return result\n\nresult = language_detection("FLUOSTEROL")\n\nprint(result)\n')),(0,r.kt)("h2",{id:"pycld2"},"Pycld2"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import pycld2 as cld2\n>>> text_content = \"\"\" A acc\xe8s aux chiens et aux frontaux qui lui ont \xe9t\xe9 il peut consulter et modifier ses collections et exporter Cet article concerne le pays europ\xe9en aujourd\u2019hui appel\xe9 R\xe9publique fran\xe7aise. \nPour d\u2019autres usages du nom France, Pour une aide rapide et effective, veuiller trouver votre aide dans le menu ci-dessus. \nWelcome, to this world of Data Scientist. Today is a lovely day.\"\"\"\n>>> _, _, _, detected_language = cld2.detect(text_content,  returnVectors=True)\n>>> print(detected_language)\n((0, 323, 'FRENCH', 'fr'), (323, 64, 'ENGLISH', 'en'))\n")),(0,r.kt)("h2",{id:"textblob"},"TextBlob"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'>>> from textblob import TextBlob\n>>> text = "\u044d\u0442\u043e \u043a\u043e\u043c\u043f\u044c\u044e\u0442\u0435\u0440\u043d\u044b\u0439 \u043f\u043e\u0440\u0442\u0430\u043b \u0434\u043b\u044f \u0433\u0438\u043a\u043e\u0432. It was a beautiful day ."\n>>> lang = TextBlob(text)\n>>> print(lang.detect_language())\nru\n')),(0,r.kt)("h2",{id:"googletrans"},"Googletrans"),(0,r.kt)("h2",{id:"resources"},"Resources"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://towardsdatascience.com/4-python-libraries-to-detect-english-and-non-english-language-c82ad3efd430"},"https://towardsdatascience.com/4-python-libraries-to-detect-english-and-non-english-language-c82ad3efd430")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://towardsdatascience.com/4-nlp-libraries-for-automatic-language-identification-of-text-data-in-python-cbc6bf664774"},"https://towardsdatascience.com/4-nlp-libraries-for-automatic-language-identification-of-text-data-in-python-cbc6bf664774"))))}u.isMDXComponent=!0}}]);
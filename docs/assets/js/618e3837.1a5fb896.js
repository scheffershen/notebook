"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[9704],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>d});var o=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,o,a=function(e,n){if(null==e)return{};var t,o,a={},i=Object.keys(e);for(o=0;o<i.length;o++)t=i[o],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(o=0;o<i.length;o++)t=i[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var s=o.createContext({}),p=function(e){var n=o.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},c=function(e){var n=p(e.components);return o.createElement(s.Provider,{value:n},e.children)},u="mdxType",g={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},m=o.forwardRef((function(e,n){var t=e.components,a=e.mdxType,i=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),u=p(t),m=a,d=u["".concat(s,".").concat(m)]||u[m]||g[m]||i;return t?o.createElement(d,r(r({ref:n},c),{},{components:t})):o.createElement(d,r({ref:n},c))}));function d(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var i=t.length,r=new Array(i);r[0]=m;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l[u]="string"==typeof e?e:a,r[1]=l;for(var p=2;p<i;p++)r[p]=t[p];return o.createElement.apply(null,r)}return o.createElement.apply(null,t)}m.displayName="MDXCreateElement"},50179:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>r,default:()=>u,frontMatter:()=>i,metadata:()=>l,toc:()=>p});var o=t(87462),a=(t(67294),t(3905));const i={},r="cloud-vision lib",l={unversionedId:"Google API/Google Vision/cloud-vision lib",id:"Google API/Google Vision/cloud-vision lib",title:"cloud-vision lib",description:"https://packagist.org/packages/google/cloud",source:"@site/docs/Google API/Google Vision/cloud-vision lib.md",sourceDirName:"Google API/Google Vision",slug:"/Google API/Google Vision/cloud-vision lib",permalink:"/notebook/docs/Google API/Google Vision/cloud-vision lib",draft:!1,editUrl:"https://github.com/scheffershen/notebook/tree/main/docs/Google API/Google Vision/cloud-vision lib.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Resources",permalink:"/notebook/docs/Google API/Google Vision/Resources"},next:{title:"cloud-vision php",permalink:"/notebook/docs/Google API/Google Vision/cloud-vision php"}},s={},p=[{value:"GoogleCloudVisionVisionClient",id:"googlecloudvisionvisionclient",level:2},{value:"Annotate a single image.",id:"annotate-a-single-image",level:3},{value:"Annotate a set of images.",id:"annotate-a-set-of-images",level:3},{value:"Image Overview",id:"image-overview",level:3},{value:"Represents a Google Cloud Vision image annotation result.",id:"represents-a-google-cloud-vision-image-annotation-result",level:3},{value:"CropHint Overview: Represents a recommended image crop.",id:"crophint-overview-represents-a-recommended-image-crop",level:2},{value:"Document Overview: Represents a Document Text Detection result.",id:"document-overview-represents-a-document-text-detection-result",level:2},{value:"Entity Overview",id:"entity-overview",level:2},{value:"SafeSearch Overview: Represents a SafeSearch annotation result",id:"safesearch-overview-represents-a-safesearch-annotation-result",level:2}],c={toc:p};function u(e){let{components:n,...t}=e;return(0,a.kt)("wrapper",(0,o.Z)({},c,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"cloud-vision-lib"},"cloud-vision lib"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://packagist.org/packages/google/cloud"},"https://packagist.org/packages/google/cloud")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"$ composer require google/cloud\n")),(0,a.kt)("h2",{id:"googlecloudvisionvisionclient"},"Google\\Cloud\\Vision\\VisionClient"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"use Google\\Cloud\\Vision\\VisionClient;\n\n$vision = new VisionClient();\n")),(0,a.kt)("h3",{id:"annotate-a-single-image"},"Annotate a single image."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"$familyPhotoResource = fopen(__DIR__ . '/assets/family-photo.jpg', 'r');\n\n$image = $vision->image($familyPhotoResource, [\n    'FACE_DETECTION'\n]);\n\n$result = $vision->annotate($image);\n")),(0,a.kt)("h3",{id:"annotate-a-set-of-images"},"Annotate a set of images."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"$images = [];\n\n$familyPhotoResource = fopen(__DIR__ . '/assets/family-photo.jpg', 'r');\n$eiffelTowerResource = fopen(__DIR__ . '/assets/eiffel-tower.jpg', 'r');\n\n$images[] = $vision->image($familyPhotoResource, [\n    'FACE_DETECTION'\n]);\n\n$images[] = $vision->image($eiffelTowerResource, [\n    'LANDMARK_DETECTION'\n]);\n\n$result = $vision->annotateBatch($images);\n")),(0,a.kt)("h3",{id:"image-overview"},"Image Overview"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"use Google\\Cloud\\Vision\\VisionClient;\n\n$vision = new VisionClient();\n\n$imageResource = fopen(__DIR__ . '/assets/family-photo.jpg', 'r');\n$image = $vision->image($imageResource, [\n    'FACE_DETECTION'\n]);\n")),(0,a.kt)("p",null,"Images can be directly instantiated."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"use Google\\Cloud\\Vision\\Image;\n\n$imageResource = fopen(__DIR__ . '/assets/family-photo.jpg', 'r');\n$image = new Image($imageResource, [\n    'FACE_DETECTION'\n]);\n")),(0,a.kt)("p",null,"Image data can be given as a string"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"use Google\\Cloud\\Vision\\Image;\n\n$imageData = file_get_contents(__DIR__ .'/assets/family-photo.jpg');\n$image = new Image($imageData, [\n   'FACE_DETECTION'\n]);\n")),(0,a.kt)("p",null,"Files stored in Google Cloud Storage can be used."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"use Google\\Cloud\\Storage\\StorageClient;\nuse Google\\Cloud\\Vision\\Image;\n\n$storage = new StorageClient();\n$file = $storage->bucket('my-test-bucket')->object('family-photo.jpg');\n$image = new Image($file, [\n    'FACE_DETECTION'\n]);\n")),(0,a.kt)("p",null,"The client library also offers shortcut names which can be used in place of the longer feature names."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"use Google\\Cloud\\Vision\\Image;\n\n$imageResource = fopen(__DIR__ . '/assets/family-photo.jpg', 'r');\n$image = new Image($imageResource, [\n    'faces',          // Corresponds to `FACE_DETECTION`\n    'landmarks',      // Corresponds to `LANDMARK_DETECTION`\n    'logos',          // Corresponds to `LOGO_DETECTION`\n    'labels',         // Corresponds to `LABEL_DETECTION`\n    'text',           // Corresponds to `TEXT_DETECTION`,\n    'document',       // Corresponds to `DOCUMENT_TEXT_DETECTION`\n    'safeSearch',     // Corresponds to `SAFE_SEARCH_DETECTION`\n    'imageProperties',// Corresponds to `IMAGE_PROPERTIES`\n    'crop',           // Corresponds to `CROP_HINTS`\n    'web'             // Corresponds to `WEB_DETECTION`\n]);\n")),(0,a.kt)("p",null,"requestObject: Return a formatted annotate image request."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"use Google\\Cloud\\Vision\\Image;\n\n$imageResource = fopen(__DIR__ . '/assets/family-photo.jpg', 'r');\n$image = new Image($imageResource, [\n    'FACE_DETECTION'\n]);\n\n$requestObj = $image->requestObject();\n")),(0,a.kt)("h3",{id:"represents-a-google-cloud-vision-image-annotation-result"},"Represents a Google Cloud Vision image annotation result."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"use Google\\Cloud\\Vision\\VisionClient;\n\n$vision = new VisionClient();\n\n$imageResource = fopen(__DIR__ . '/assets/family-photo.jpg', 'r');\n$image = $vision->image($imageResource, [\n    'FACE_DETECTION'\n]);\n\n$annotation = $vision->annotate($image);\n")),(0,a.kt)("p",null,"Fetch Crop Hints"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"$hints = $annotation->cropHints();\n")),(0,a.kt)("p",null,"Return the full text annotation."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"$fullText = $annotation->fullText();\n")),(0,a.kt)("p",null,"Get the result of a safe search detection"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"$safeSearch = $annotation->safeSearch();\n")),(0,a.kt)("p",null,"Return an array containing all text found in the image"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"$text = $annotation->text();\n")),(0,a.kt)("h2",{id:"crophint-overview-represents-a-recommended-image-crop"},"CropHint Overview: Represents a recommended image crop."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"use Google\\Cloud\\Vision\\VisionClient;\n\n$vision = new VisionClient();\n\n$imageResource = fopen(__DIR__ . '/assets/family-photo.jpg', 'r');\n$image = $vision->image($imageResource, [ 'CROP_HINTS' ]);\n$annotation = $vision->annotate($image);\n\n$hints = $annotation->cropHints();\n$hint = $hints[0];\n")),(0,a.kt)("p",null,"boundingPoly: The bounding polygon of the recommended crop."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"$poly = $hint->boundingPoly();\n")),(0,a.kt)("h2",{id:"document-overview-represents-a-document-text-detection-result"},"Document Overview: Represents a Document Text Detection result."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"use Google\\Cloud\\Vision\\VisionClient;\n\n$vision = new VisionClient();\n\n$imageResource = fopen(__DIR__ . '/assets/the-constitution.jpg', 'r');\n$image = $vision->image($imageResource, [ 'DOCUMENT_TEXT_DETECTION' ]);\n$annotation = $vision->annotate($image);\n\n$document = $annotation->fullText();\n")),(0,a.kt)("p",null,"pages: Get the document pages."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"$pages = $document->pages();\n")),(0,a.kt)("p",null,"test: Get the document text."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"$text = $document->text();\n")),(0,a.kt)("h2",{id:"entity-overview"},"Entity Overview"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"use Google\\Cloud\\Vision\\VisionClient;\n\n$vision = new VisionClient();\n\n$imageResource = fopen(__DIR__ . '/assets/family-photo.jpg', 'r');\n$image = $vision->image($imageResource, [ 'text' ]);\n$annotation = $vision->annotate($image);\n\n$text = $annotation->text()[0];\n")),(0,a.kt)("p",null,"For TEXT_DETECTION (OCR), boundingPolys are produced for the entire text detected in an image region, followed by boundingPolys for each word within the detected text."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"print_r($text->boundingPoly());\n")),(0,a.kt)("p",null,"For example, for an image containing 'Eiffel Tower,' this field represents the confidence that there is a tower in the query image."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"echo $text->confidence();\n")),(0,a.kt)("p",null,"Entity textual description, expressed in its locale language."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"echo $text->description();\n")),(0,a.kt)("p",null,"Get the raw annotation result"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"$info = $text->info();\n")),(0,a.kt)("p",null,"The language code for the locale in which the entity textual description (next field) is expressed."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"echo $text->locale();\n")),(0,a.kt)("p",null,"Some IDs might be available in Knowledge Graph(KG)."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"echo $text->mid();\n")),(0,a.kt)("h2",{id:"safesearch-overview-represents-a-safesearch-annotation-result"},"SafeSearch Overview: Represents a SafeSearch annotation result"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},"use Google\\Cloud\\Vision\\VisionClient;\n\n$vision = new VisionClient();\n\n$imageResource = fopen(__DIR__ . '/assets/family-photo.jpg', 'r');\n$image = $vision->image($imageResource, [ 'safeSearch' ]);\n$annotation = $vision->annotate($image);\n\n$safeSearch = $annotation->safeSearch();\n")),(0,a.kt)("p",null,"isMedical: Check whether the image contains medical content"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-php"},'if ($safeSearch->medical()) {\n    echo "Image contains medical content.";\n}\n')))}u.isMDXComponent=!0}}]);
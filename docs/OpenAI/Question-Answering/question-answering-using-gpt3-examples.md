question-answering-using-gpt3-examples
======================================

2023-01

- https://www.pragnakalp.com/question-answering-using-gpt3-examples/
- https://www.pinecone.io/learn/openai-gen-qa/

For any existing knowledgebase for your product or service, it is easier than ever to create an AI powered add-on that can search the knowledgebase and answer questions in natural language.

Using GPT-3 (developed by OpenAI), one can easily build an API driven service with great results, without actually learning or implementing any Machine Learning code or putting heavy compute power to support it.

## OpenAI

OpenAI is an artificial intelligence (AI) research laboratory consisting of the for-profit corporation OpenAI LP and its parent company, the non-profit OpenAI Inc. — Wikipedia

## GPT-3

`Generative Pre-trained Transformer 3` (GPT-3) is an autoregressive language model that uses deep learning to produce human-like text. — Wikipedia.

GPT-3 is the third-generation language prediction model developed by OpenAI. 

It is said that the quality of text generated by GPT-3 is so high, that it can be very difficult to determine if it was generated by a human or AI. 

Now, let’s see how we can use GPT-3 to create an answering service on top of our existing knowledgebase.

## Signup at OpenAI and get an API Key

## How to use GPT-3 Question Answering

Create & Activate virtualenv

   $ py -3.9 -m 

1. Let’s explore how we can perform question answering using a document list 

```python
import openai
openai.api_key = "YOUR-API-KEY"
 
document_list = ["Google was founded in 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University in California. Together they own about 14 percent of its shares and control 56 percent of the stockholder voting power through supervoting stock. They incorporated Google as a privately held company on September 4, 1998. An initial public offering (IPO) took place on August 19, 2004, and Google moved to its headquarters in Mountain View, California, nicknamed the Googleplex. In August 2015, Google announced plans to reorganize its various interests as a conglomerate called Alphabet Inc. Google is Alphabet's leading subsidiary and will continue to be the umbrella company for Alphabet's Internet interests. Sundar Pichai was appointed CEO of Google, replacing Larry Page who became the CEO of Alphabet.",
"Amazon is an American multinational technology company based in Seattle, Washington, which focuses on e-commerce, cloud computing, digital streaming, and artificial intelligence. It is one of the Big Five companies in the U.S. information technology industry, along with Google, Apple, Microsoft, and Facebook. The company has been referred to as 'one of the most influential economic and cultural forces in the world', as well as the world's most valuable brand. Jeff Bezos founded Amazon from his garage in Bellevue, Washington on July 5, 1994. It started as an online marketplace for books but expanded to sell electronics, software, video games, apparel, furniture, food, toys, and jewelry. In 2015, Amazon surpassed Walmart as the most valuable retailer in the United States by market capitalization."]
 
response = openai.Answer.create(
 search_model="ada",
 model="curie",
 question="when was google founded?",
 documents=document_list,
 examples_context="In 2017, U.S. life expectancy was 78.6 years.",
 examples=[["What is human life expectancy in the United States?","78 years."]],
 max_tokens=10,
 stop=["\n", "<|endoftext|>"],
)
 
print(response)

```

2. Let’s see how we can perform Question Answering using data stored in File :

You can create a .jsonl(JSON Lines) files where each JSON line contains the `text` field and `metadata` field(optional). 

   {"text": "Hello OpenAI", "metadata": "sample data"}

Once you have created the jsonl file, now you need to upload that file.

```python
import openai
openai.api_key = "YOUR-API-KEY"
 
response = openai.File.create(
 file=open("sample_qna.jsonl"),
 purpose='answers'
)
 
print(response)
```

From the above response, we will need the file ID

```python
import openai
openai.api_key = "YOUR-API-KEY"
 
response = openai.Answer.create(
   search_model="ada",
   model="curie",
   question="when was google founded?",
   file="file-h5zzNVGdUigntPQWeVmJqAJf",
   examples_context="In 2017, U.S. life expectancy was 78.6 years.",
   examples=[["What is human life expectancy in the United States?","78 years."]],
   max_rerank=10,
   max_tokens=10,
   stop=["\n", "<|endoftext|>"]
 
)
 
print(response)
```

NOTE : you can specify either file or document not both

### More examples

example 1:

```python
import openai
openai.api_key = "YOUR-API-KEY"

query = "who was the 12th person on the moon and when did they land?"

# now query text-davinci-003 WITHOUT context
res = openai.Completion.create(
    engine='text-davinci-003',
    prompt=query,
    temperature=0,
    max_tokens=400,
    top_p=1,
    frequency_penalty=0,
    presence_penalty=0,
    stop=None
)

res['choices'][0]['text'].strip()
```

example 2:

```python
import openai
openai.api_key = "YOUR-API-KEY"

# first let's make it simpler to get answers
def complete(prompt):
    # query text-davinci-003
    res = openai.Completion.create(
        engine='text-davinci-003',
        prompt=prompt,
        temperature=0,
        max_tokens=400,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None
    )
    return res['choices'][0]['text'].strip()

query = (
    "Which training method should I use for sentence transformers when " +
    "I only have pairs of related sentences?"
)

complete(query)
```

### Building a Knowledge Base

We refer to knowledge bases that can enable the retrieval of semantically relevant information as vector databases.

A vector database stores vector representations of information encoded using specific ML models.

These models have an “understanding” of language and can encode passages with similar meanings into a similar vector space and dissimilar passages into a dissimilar vector space.

Weaviate is an open-source vector search engine.

```python
embed_model = "text-embedding-ada-002"

res = openai.Embedding.create(
    input=[
        "Sample document text goes here",
        "there will be several phrases in each batch"
    ], engine=embed_model
)

# vector embeddings are stored within the 'data' key
res.keys()

dict_keys(['object', 'data', 'model', 'usage'])

# we have created two 1536-dimensional vectors
len(res['data'][0]['embedding']), len(res['data'][1]['embedding'])
```

### Data Preparation

The dataset we will use in our knowledge base is the jamescalam/youtube-transcriptions dataset hosted on Hugging Face Datasets

```python
from datasets import load_dataset

data = load_dataset('jamescalam/youtube-transcriptions', split='train')
data

data[0]

#The dataset contains many small snippets of text data. We need to merge several snippets to create more substantial chunks of text that contain more meaningful information.
from tqdm.auto import tqdm

new_data = []

window = 20  # number of sentences to combine
stride = 4  # number of sentences to 'stride' over, used to create overlap

for i in tqdm(range(0, len(data), stride)):
    i_end = min(len(data)-1, i+window)
    if data[i]['title'] != data[i_end]['title']:
        # in this case we skip this entry as we have start/end of two videos
        continue
    text = ' '.join(data[i:i_end]['text'])
    # create the new merged dataset
    new_data.append({
        'start': data[i]['start'],
        'end': data[i_end]['end'],
        'title': data[i]['title'],
        'text': text,
        'id': data[i]['id'],
        'url': data[i]['url'],
        'published': data[i]['published'],
        'channel_id': data[i]['channel_id']
    })

new_data[0]

#Creating the Vector Database
#The vector database is the storage and retrieval component in our pipeline.
import pinecone

index_name = 'openai-youtube-transcriptions'

# initialize connection (get API key at app.pinecone.io)
pinecone.init(
    api_key="YOUR_API_KEY",
    environment="YOUR_ENV"  # find next to API key
)

# check if index already exists (it shouldn't if this is first time)
if index_name not in pinecone.list_indexes():
    # if does not exist, create index
    pinecone.create_index(
        index_name,
        dimension=len(res['data'][0]['embedding']),
        metric='cosine',
        metadata_config={
            'indexed': ['channel_id', 'published']
        }
    )
# connect to index
index = pinecone.Index(index_name)
# view index stats
index.describe_index_stats()

#Then we embed and index a dataset like so:
from tqdm.auto import tqdm
import datetime
from time import sleep

batch_size = 100  # how many embeddings we create and insert at once

for i in tqdm(range(0, len(new_data), batch_size)):
    # find end of batch
    i_end = min(len(new_data), i+batch_size)
    meta_batch = new_data[i:i_end]
    # get ids
    ids_batch = [x['id'] for x in meta_batch]
    # get texts to encode
    texts = [x['text'] for x in meta_batch]
    # create embeddings (try-except added to avoid RateLimitError)
    try:
        res = openai.Embedding.create(input=texts, engine=embed_model)
    except:
        done = False
        while not done:
            sleep(5)
            try:
                res = openai.Embedding.create(input=texts, engine=embed_model)
                done = True
            except:
                pass
    embeds = [record['embedding'] for record in res['data']]
    # cleanup metadata
    meta_batch = [{
        'start': x['start'],
        'end': x['end'],
        'title': x['title'],
        'text': x['text'],
        'url': x['url'],
        'published': x['published'],
        'channel_id': x['channel_id']
    } for x in meta_batch]
    to_upsert = list(zip(ids_batch, embeds, meta_batch))
    # upsert to Pinecone
    index.upsert(vectors=to_upsert)

#We’re ready to combine OpenAI’s Completion and Embedding endpoints with our Pinecone vector database to create a retrieval-augmented GQA system.
#Query => .Embedding() => Vector DB => Context-enhanced Query => .Completion() => Response
res = openai.Embedding.create(
    input=[query],
    engine=embed_model
)

# retrieve from Pinecone
xq = res['data'][0]['embedding']

# get relevant contexts (including the questions)
res = index.query(xq, top_k=2, include_metadata=True)

limit = 3750

def retrieve(query):
    res = openai.Embedding.create(
        input=[query],
        engine=embed_model
    )

    # retrieve from Pinecone
    xq = res['data'][0]['embedding']

    # get relevant contexts
    res = index.query(xq, top_k=3, include_metadata=True)
    contexts = [
        x['metadata']['text'] for x in res['matches']
    ]

    # build our prompt with the retrieved contexts included
    prompt_start = (
        "Answer the question based on the context below.\n\n"+
        "Context:\n"
    )
    prompt_end = (
        f"\n\nQuestion: {query}\nAnswer:"
    )
    # append contexts until hitting limit
    for i in range(1, len(contexts)):
        if len("\n\n---\n\n".join(contexts[:i])) >= limit:
            prompt = (
                prompt_start +
                "\n\n---\n\n".join(contexts[:i-1]) +
                prompt_end
            )
            break
        elif i == len(contexts)-1:
            prompt = (
                prompt_start +
                "\n\n---\n\n".join(contexts) +
                prompt_end
            )
    return prompt


# first we retrieve relevant items from Pinecone
query_with_contexts = retrieve(query)
query_with_contexts

# then we complete the context-infused query
complete(query_with_contexts)
```

      jamescalam/youtube-transcriptions = Dataset({
          features: ['title', 'published', 'url', 'video_id', 'channel_id', 'id', 'text', 'start', 'end'],
          num_rows: 208619
      })

      data[0] = {'title': 'Training and Testing an Italian BERT - Transformers From Scratch #4',
          'published': '2021-07-06 13:00:03 UTC',
          'url': 'https://youtu.be/35Pdoyi6ZoQ',
          'video_id': '35Pdoyi6ZoQ',
          'channel_id': 'UCv83tO5cePwHMt1952IVVHw',
          'id': '35Pdoyi6ZoQ-t0.0',
          'text': 'Hi, welcome to the video.',
          'start': 0.0,
          'end': 9.36
      }

      new_data[0] = {'start': 0.0,
          'end': 74.12,
          'title': 'Training and Testing an Italian BERT - Transformers From Scratch #4',
          'text': "Hi, welcome to the video. So this is the fourth video in a Transformers from Scratch mini series. So if you haven't been following along, we've essentially covered what you can see on the screen. So we got some data. We built a tokenizer with it. And then we've set up our input pipeline ready to begin actually training our model, which is what we're going to cover in this video. So let's move over to the code. And we see here that we have essentially everything we've done so far. So we've built our input data, our input pipeline. And we're now at a point where we have a data loader, PyTorch data loader, ready. And we can begin training a model with it. So there are a few things to be aware of. So I mean, first, let's just have a quick look at the structure of our data.",
          'id': '35Pdoyi6ZoQ-t0.0',
          'url': 'https://youtu.be/35Pdoyi6ZoQ',
          'published': '2021-07-06 13:00:03 UTC',
          'channel_id': 'UCv83tO5cePwHMt1952IVVHw'
      }

      index.describe_index_stats() = {'dimension': 1536,
          'index_fullness': 0.0,
          'namespaces': {},
          'total_vector_count': 0
      }